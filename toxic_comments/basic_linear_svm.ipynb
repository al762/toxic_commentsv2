{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comments_preprocessing(df):\n",
    "    df['comment_text'] = df['comment_text'].apply(lambda x: str(x))\n",
    "    df['comment_text'] = df['comment_text'].apply(lambda x: x.lower())\n",
    "    df['comment_text'] = df['comment_text'].apply(lambda x: x.translate(str.maketrans('','',string.punctuation)))\n",
    "    df['comment_text'] = df['comment_text'].apply(lambda x: x.replace('\\n',''))\n",
    "    df['comment_text'] = df['comment_text'].apply(lambda x: x.replace('\\r',''))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape (95851, 8)\n",
      "test shape (226998, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6044863</td>\n",
       "      <td>orphaned nonfree media image41cd1jboevl ss500 jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6102620</td>\n",
       "      <td>kentuckiana is colloquial  even though the are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14563293</td>\n",
       "      <td>hello fellow wikipediansi have just modified  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21086297</td>\n",
       "      <td>akc suspensions the morning call  feb 24 2001 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22982444</td>\n",
       "      <td>wikilink talkcelts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                       comment_text\n",
       "0   6044863  orphaned nonfree media image41cd1jboevl ss500 jpg\n",
       "1   6102620  kentuckiana is colloquial  even though the are...\n",
       "2  14563293  hello fellow wikipediansi have just modified  ...\n",
       "3  21086297  akc suspensions the morning call  feb 24 2001 ...\n",
       "4  22982444                                wikilink talkcelts "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "train = comments_preprocessing(train)\n",
    "test = pd.read_csv('data/test.csv')\n",
    "test = comments_preprocessing(test)\n",
    "\n",
    "print('train shape', train.shape)\n",
    "print('test shape', test.shape)\n",
    "train.head()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further preprocessing: <br>\n",
    "- add in lemmatization and stemming subsequently. <br>\n",
    "- remove low frequency words / words that only occur once or twice after stemming?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
     ]
    }
   ],
   "source": [
    "categories = train.columns.values.tolist()[2:]\n",
    "toxic_dataframes = [train[train[x] == 1] for x in categories]\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic (9237, 8)\n",
      "severe_toxic (965, 8)\n",
      "obscene (5109, 8)\n",
      "threat (305, 8)\n",
      "insult (4765, 8)\n",
      "identity_hate (814, 8)\n",
      "predictions shape (226998, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6044863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6102620</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14563293</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21086297</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22982444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24388733</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26195914</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31769073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35289443</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38393350</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>51720630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>52808210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>53780387</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>55969236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>59321043</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>59993753</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>60087415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>62246374</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>63082469</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>66675140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0    6044863      0             0        0       0       0              0\n",
       "1    6102620      0             0        0       0       0              0\n",
       "2   14563293      0             0        0       0       0              0\n",
       "3   21086297      0             0        0       0       0              0\n",
       "4   22982444      0             0        0       0       0              0\n",
       "5   24388733      0             0        0       0       0              0\n",
       "6   26195914      0             0        0       0       0              0\n",
       "7   31769073      0             0        0       0       0              0\n",
       "8   35289443      0             0        0       0       0              0\n",
       "9   38393350      0             0        0       0       0              0\n",
       "10  51720630      0             0        0       0       0              0\n",
       "11  52808210      0             0        1       0       0              0\n",
       "12  53780387      0             0        0       0       0              0\n",
       "13  55969236      0             0        0       0       0              0\n",
       "14  59321043      0             0        0       0       0              0\n",
       "15  59993753      0             0        0       0       0              0\n",
       "16  60087415      0             0        0       0       0              0\n",
       "17  62246374      0             0        0       0       0              0\n",
       "18  63082469      0             0        0       0       0              0\n",
       "19  66675140      0             0        0       0       0              0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame({'id': test['id']})\n",
    "\n",
    "for i, name in enumerate(categories):\n",
    "    print(name, toxic_dataframes[i].shape)\n",
    "    clf = Pipeline([('tfidf', TfidfVectorizer()), ('svc', LinearSVC(loss='hinge'))])\n",
    "    clf.fit(train['comment_text'], train[name])\n",
    "    pred = clf.predict(test['comment_text'])\n",
    "    predictions[name] = pred\n",
    "\n",
    "print('predictions shape', predictions.shape)\n",
    "predictions.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x10cdfcd20, file \"/ana...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10cdfcd20, file \"/ana...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"parameters = {'svc__tol': [1e-5,1e-2], 'svc__C':..._clf.fit(train['comment_text'], train['toxic'])\\n\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 29, 0, 56, 5, 999549, tzinfo=tzutc()), 'msg_id': '140F2A2F11954948953760F92639355D', 'msg_type': 'execute_request', 'session': '421A6F6215CC4FD2884C42E370C07DCB', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '140F2A2F11954948953760F92639355D', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'421A6F6215CC4FD2884C42E370C07DCB']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"parameters = {'svc__tol': [1e-5,1e-2], 'svc__C':..._clf.fit(train['comment_text'], train['toxic'])\\n\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 29, 0, 56, 5, 999549, tzinfo=tzutc()), 'msg_id': '140F2A2F11954948953760F92639355D', 'msg_type': 'execute_request', 'session': '421A6F6215CC4FD2884C42E370C07DCB', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '140F2A2F11954948953760F92639355D', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'421A6F6215CC4FD2884C42E370C07DCB'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"parameters = {'svc__tol': [1e-5,1e-2], 'svc__C':..._clf.fit(train['comment_text'], train['toxic'])\\n\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 29, 0, 56, 5, 999549, tzinfo=tzutc()), 'msg_id': '140F2A2F11954948953760F92639355D', 'msg_type': 'execute_request', 'session': '421A6F6215CC4FD2884C42E370C07DCB', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '140F2A2F11954948953760F92639355D', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"parameters = {'svc__tol': [1e-5,1e-2], 'svc__C':..._clf.fit(train['comment_text'], train['toxic'])\\n\\n\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"parameters = {'svc__tol': [1e-5,1e-2], 'svc__C':..._clf.fit(train['comment_text'], train['toxic'])\\n\\n\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"parameters = {'svc__tol': [1e-5,1e-2], 'svc__C':..._clf.fit(train['comment_text'], train['toxic'])\\n\\n\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"parameters = {'svc__tol': [1e-5,1e-2], 'svc__C':..._clf.fit(train['comment_text'], train['toxic'])\\n\\n\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"parameters = {'svc__tol': [1e-5,1e-2], 'svc__C':..._clf.fit(train['comment_text'], train['toxic'])\\n\\n\", store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-43-a075af577231>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1a19993198, execution..._before_exec=None error_in_exec=None result=None>)\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n   2807                 code = compiler(mod, cell_name, \"single\")\n-> 2808                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1155830c0, file \"<ipython-input-43-a075af577231>\", line 3>\n        result = <ExecutionResult object at 1a19993198, execution..._before_exec=None error_in_exec=None result=None>\n   2809                     return True\n   2810 \n   2811             # Flush softspace\n   2812             if softspace(sys.stdout, 0):\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1155830c0, file \"<ipython-input-43-a075af577231>\", line 3>, result=<ExecutionResult object at 1a19993198, execution..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1155830c0, file \"<ipython-input-43-a075af577231>\", line 3>\n        self.user_global_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport numpy as np\\nimport st....svm import LinearSVC\\nfrom sklearn.svm import SVC', \"def comments_preprocessing(df):\\n    df['comment_...apply(lambda x: x.replace('\\\\r',''))\\n    return df\", \"train = pd.read_csv('data/train.csv')\\ntrain = co...test shape', test.shape)\\ntrain.head()\\ntest.head()\", 'categories = train.columns.values.tolist()[2:]\\nt...n[x] == 1] for x in categories]\\nprint(categories)', \"predictions = pd.DataFrame({'id': test['id']})\\n\\n...s shape', predictions.shape)\\npredictions.head(20)\", \"predictions = pd.DataFrame({'id': test['id']})\\n\\n...s shape', predictions.shape)\\npredictions.head(20)\", \"print('amount marked true in each category')\\nfor... = predictions[name].sum()\\n    print(name, total)\", \"print('amount marked true in each category')\\nfor... = predictions[name].sum()\\n    print(name, total)\", 'import pandas as pd\\nimport numpy as np\\nimport st...\\nfrom sklearn.model_selection import GridSearchCV', 'import pandas as pd\\nimport numpy as np\\nimport st...\\nfrom sklearn.model_selection import GridSearchCV', 'import pandas as pd\\nimport numpy as np\\nimport st...\\nfrom sklearn.model_selection import GridSearchCV', \"def comments_preprocessing(df):\\n    df['comment_...apply(lambda x: x.replace('\\\\r',''))\\n    return df\", \"train = pd.read_csv('data/train.csv')\\ntrain = co...test shape', test.shape)\\ntrain.head()\\ntest.head()\", 'categories = train.columns.values.tolist()[2:]\\nt...n[x] == 1] for x in categories]\\nprint(categories)', \"parameters = {'C': (-1,1), 'tol': (1e-4,1e-2))}\\n... % (param_name, gs_clf.best_params_[param_name]))\", \"parameters = {'C': (-1,1), 'tol': (1e-4,1e-2)}\\nf... % (param_name, gs_clf.best_params_[param_name]))\", \"parameters = {'C': (0,1), 'tol': (1e-4,1e-2)}\\nfo... % (param_name, gs_clf.best_params_[param_name]))\", \"parameters = {'tol': (1e-4,1e-2)}\\nfor name in ca... % (param_name, gs_clf.best_params_[param_name]))\", \"parameters = {'svc__tol': (1e-4,1e-2)}\\nfor name ... % (param_name, gs_clf.best_params_[param_name]))\", ...], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'Out': {3:          id                                     ...                              wikilink talkcelts , 5:           id  toxic  severe_toxic  obscene  thre...        0        0       0       0              0, 6:           id  toxic  severe_toxic  obscene  thre...        0        0       0       0              0, 13:          id                                     ...                              wikilink talkcelts , 21:          id                                     ...                              wikilink talkcelts , 23:           id  toxic  severe_toxic  obscene  thre...        0        0       0       0              0, 36: GridSearchCV(cv=None, error_score='raise',\n     ...turn_train_score='warn', scoring=None, verbose=0)}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'TfidfTransformer': <class 'sklearn.feature_extraction.text.TfidfTransformer'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, '_': GridSearchCV(cv=None, error_score='raise',\n     ...turn_train_score='warn', scoring=None, verbose=0), ...}\n        self.user_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport numpy as np\\nimport st....svm import LinearSVC\\nfrom sklearn.svm import SVC', \"def comments_preprocessing(df):\\n    df['comment_...apply(lambda x: x.replace('\\\\r',''))\\n    return df\", \"train = pd.read_csv('data/train.csv')\\ntrain = co...test shape', test.shape)\\ntrain.head()\\ntest.head()\", 'categories = train.columns.values.tolist()[2:]\\nt...n[x] == 1] for x in categories]\\nprint(categories)', \"predictions = pd.DataFrame({'id': test['id']})\\n\\n...s shape', predictions.shape)\\npredictions.head(20)\", \"predictions = pd.DataFrame({'id': test['id']})\\n\\n...s shape', predictions.shape)\\npredictions.head(20)\", \"print('amount marked true in each category')\\nfor... = predictions[name].sum()\\n    print(name, total)\", \"print('amount marked true in each category')\\nfor... = predictions[name].sum()\\n    print(name, total)\", 'import pandas as pd\\nimport numpy as np\\nimport st...\\nfrom sklearn.model_selection import GridSearchCV', 'import pandas as pd\\nimport numpy as np\\nimport st...\\nfrom sklearn.model_selection import GridSearchCV', 'import pandas as pd\\nimport numpy as np\\nimport st...\\nfrom sklearn.model_selection import GridSearchCV', \"def comments_preprocessing(df):\\n    df['comment_...apply(lambda x: x.replace('\\\\r',''))\\n    return df\", \"train = pd.read_csv('data/train.csv')\\ntrain = co...test shape', test.shape)\\ntrain.head()\\ntest.head()\", 'categories = train.columns.values.tolist()[2:]\\nt...n[x] == 1] for x in categories]\\nprint(categories)', \"parameters = {'C': (-1,1), 'tol': (1e-4,1e-2))}\\n... % (param_name, gs_clf.best_params_[param_name]))\", \"parameters = {'C': (-1,1), 'tol': (1e-4,1e-2)}\\nf... % (param_name, gs_clf.best_params_[param_name]))\", \"parameters = {'C': (0,1), 'tol': (1e-4,1e-2)}\\nfo... % (param_name, gs_clf.best_params_[param_name]))\", \"parameters = {'tol': (1e-4,1e-2)}\\nfor name in ca... % (param_name, gs_clf.best_params_[param_name]))\", \"parameters = {'svc__tol': (1e-4,1e-2)}\\nfor name ... % (param_name, gs_clf.best_params_[param_name]))\", ...], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'Out': {3:          id                                     ...                              wikilink talkcelts , 5:           id  toxic  severe_toxic  obscene  thre...        0        0       0       0              0, 6:           id  toxic  severe_toxic  obscene  thre...        0        0       0       0              0, 13:          id                                     ...                              wikilink talkcelts , 21:          id                                     ...                              wikilink talkcelts , 23:           id  toxic  severe_toxic  obscene  thre...        0        0       0       0              0, 36: GridSearchCV(cv=None, error_score='raise',\n     ...turn_train_score='warn', scoring=None, verbose=0)}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'TfidfTransformer': <class 'sklearn.feature_extraction.text.TfidfTransformer'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, '_': GridSearchCV(cv=None, error_score='raise',\n     ...turn_train_score='warn', scoring=None, verbose=0), ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/Users/alanliang/Desktop/toxic_comments/<ipython-input-43-a075af577231> in <module>()\n      1 parameters = {'svc__tol': [1e-5,1e-2], 'svc__C':[0,1]}\n      2 gs_clf = GridSearchCV(clf, parameters, n_jobs = -1)\n----> 3 gs_clf.fit(train['comment_text'], train['toxic'])\n      4 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...ain_score='warn',\n       scoring=None, verbose=0), X=0        nonsense  kiss off geek what i said is ...\nName: comment_text, Length: 95851, dtype: object, y=0        1\n1        0\n2        0\n3        0\n4   ...850    0\nName: toxic, Length: 95851, dtype: int64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = 0        nonsense  kiss off geek what i said is ...\nName: comment_text, Length: 95851, dtype: object\n        y = 0        1\n1        0\n2        0\n3        0\n4   ...850    0\nName: toxic, Length: 95851, dtype: int64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Thu Dec 28 18:56:16 2017\nPID: 3178                               Python 3.6.3: /anaconda3/bin/python\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('tfidf', Tfid...'l2', random_state=None, tol=1e-05, verbose=0))]), 0        nonsense  kiss off geek what i said is ...\nName: comment_text, Length: 95851, dtype: object, 0        1\n1        0\n2        0\n3        0\n4   ...850    0\nName: toxic, Length: 95851, dtype: int64, {'score': <function _passthrough_scorer>}, array([31887, 31888, 31898, ..., 95848, 95849, 95850]), array([    0,     1,     2, ..., 31964, 31965, 31966]), 0, {'svc__C': 0, 'svc__tol': 1e-05}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('tfidf', Tfid...'l2', random_state=None, tol=1e-05, verbose=0))]), 0        nonsense  kiss off geek what i said is ...\nName: comment_text, Length: 95851, dtype: object, 0        1\n1        0\n2        0\n3        0\n4   ...850    0\nName: toxic, Length: 95851, dtype: int64, {'score': <function _passthrough_scorer>}, array([31887, 31888, 31898, ..., 95848, 95849, 95850]), array([    0,     1,     2, ..., 31964, 31965, 31966]), 0, {'svc__C': 0, 'svc__tol': 1e-05})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...'l2', random_state=None, tol=1e-05, verbose=0))]), X=0        nonsense  kiss off geek what i said is ...\nName: comment_text, Length: 95851, dtype: object, y=0        1\n1        0\n2        0\n3        0\n4   ...850    0\nName: toxic, Length: 95851, dtype: int64, scorer={'score': <function _passthrough_scorer>}, train=array([31887, 31888, 31898, ..., 95848, 95849, 95850]), test=array([    0,     1,     2, ..., 31964, 31965, 31966]), verbose=0, parameters={'svc__C': 0, 'svc__tol': 1e-05}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...l2', random_state=None, tol=1e-05, verbose=0))])>\n        X_train = 31887    you are  really a dishonest person ive ...\nName: comment_text, Length: 63900, dtype: object\n        y_train = 31887    1\n31888    1\n31898    1\n31907    1\n3191...850    0\nName: toxic, Length: 63900, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...'l2', random_state=None, tol=1e-05, verbose=0))]), X=31887    you are  really a dishonest person ive ...\nName: comment_text, Length: 63900, dtype: object, y=31887    1\n31888    1\n31898    1\n31907    1\n3191...850    0\nName: toxic, Length: 63900, dtype: int64, **fit_params={})\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n    248         Xt, fit_params = self._fit(X, y, **fit_params)\n    249         if self._final_estimator is not None:\n--> 250             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method LinearSVC.fit of LinearSVC(C=0, cl...y='l2', random_state=None, tol=1e-05, verbose=0)>\n        Xt = <63900x159435 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>\n        y = 31887    1\n31888    1\n31898    1\n31907    1\n3191...850    0\nName: toxic, Length: 63900, dtype: int64\n        fit_params = {}\n    251         return self\n    252 \n    253     def fit_transform(self, X, y=None, **fit_params):\n    254         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/svm/classes.py in fit(self=LinearSVC(C=0, class_weight=None, dual=True, fit...ty='l2', random_state=None, tol=1e-05, verbose=0), X=<63900x159435 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, y=array([1, 1, 1, ..., 0, 0, 0]), sample_weight=None)\n    230 \n    231         self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n    232             X, y, self.C, self.fit_intercept, self.intercept_scaling,\n    233             self.class_weight, self.penalty, self.dual, self.verbose,\n    234             self.max_iter, self.tol, self.random_state, self.multi_class,\n--> 235             self.loss, sample_weight=sample_weight)\n        self.loss = 'hinge'\n        sample_weight = None\n    236 \n    237         if self.multi_class == \"crammer_singer\" and len(self.classes_) == 2:\n    238             self.coef_ = (self.coef_[1] - self.coef_[0]).reshape(1, -1)\n    239             if self.fit_intercept:\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py in _fit_liblinear(X=<63900x159435 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, y=array([1, 1, 1, ..., 0, 0, 0]), C=0, fit_intercept=True, intercept_scaling=1, class_weight=None, penalty='l2', dual=True, verbose=0, max_iter=1000, tol=1e-05, random_state=None, multi_class='ovr', loss='hinge', epsilon=0.1, sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.]))\n    885 \n    886     solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n    887     raw_coef_, n_iter_ = liblinear.train_wrap(\n    888         X, y_ind, sp.isspmatrix(X), solver_type, tol, bias, C,\n    889         class_weight_, max_iter, rnd.randint(np.iinfo('i').max),\n--> 890         epsilon, sample_weight)\n        epsilon = 0.1\n        sample_weight = array([ 1.,  1.,  1., ...,  1.,  1.,  1.])\n    891     # Regarding rnd.randint(..) in the above signature:\n    892     # seed for srand in range [0..INT_MAX); due to limitations in Numpy\n    893     # on 32-bit platforms, we can't get to the UINT_MAX limit that\n    894     # srand supports\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/svm/liblinear.cpython-36m-darwin.so in sklearn.svm.liblinear.train_wrap()\n\nValueError: b'C <= 0'\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\", line 250, in fit\n    self._final_estimator.fit(Xt, y, **fit_params)\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/svm/classes.py\", line 235, in fit\n    self.loss, sample_weight=sample_weight)\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py\", line 890, in _fit_liblinear\n    epsilon, sample_weight)\n  File \"sklearn/svm/liblinear.pyx\", line 51, in sklearn.svm.liblinear.train_wrap\nValueError: b'C <= 0'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Thu Dec 28 18:56:16 2017\nPID: 3178                               Python 3.6.3: /anaconda3/bin/python\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('tfidf', Tfid...'l2', random_state=None, tol=1e-05, verbose=0))]), 0        nonsense  kiss off geek what i said is ...\nName: comment_text, Length: 95851, dtype: object, 0        1\n1        0\n2        0\n3        0\n4   ...850    0\nName: toxic, Length: 95851, dtype: int64, {'score': <function _passthrough_scorer>}, array([31887, 31888, 31898, ..., 95848, 95849, 95850]), array([    0,     1,     2, ..., 31964, 31965, 31966]), 0, {'svc__C': 0, 'svc__tol': 1e-05}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('tfidf', Tfid...'l2', random_state=None, tol=1e-05, verbose=0))]), 0        nonsense  kiss off geek what i said is ...\nName: comment_text, Length: 95851, dtype: object, 0        1\n1        0\n2        0\n3        0\n4   ...850    0\nName: toxic, Length: 95851, dtype: int64, {'score': <function _passthrough_scorer>}, array([31887, 31888, 31898, ..., 95848, 95849, 95850]), array([    0,     1,     2, ..., 31964, 31965, 31966]), 0, {'svc__C': 0, 'svc__tol': 1e-05})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...'l2', random_state=None, tol=1e-05, verbose=0))]), X=0        nonsense  kiss off geek what i said is ...\nName: comment_text, Length: 95851, dtype: object, y=0        1\n1        0\n2        0\n3        0\n4   ...850    0\nName: toxic, Length: 95851, dtype: int64, scorer={'score': <function _passthrough_scorer>}, train=array([31887, 31888, 31898, ..., 95848, 95849, 95850]), test=array([    0,     1,     2, ..., 31964, 31965, 31966]), verbose=0, parameters={'svc__C': 0, 'svc__tol': 1e-05}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...l2', random_state=None, tol=1e-05, verbose=0))])>\n        X_train = 31887    you are  really a dishonest person ive ...\nName: comment_text, Length: 63900, dtype: object\n        y_train = 31887    1\n31888    1\n31898    1\n31907    1\n3191...850    0\nName: toxic, Length: 63900, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...'l2', random_state=None, tol=1e-05, verbose=0))]), X=31887    you are  really a dishonest person ive ...\nName: comment_text, Length: 63900, dtype: object, y=31887    1\n31888    1\n31898    1\n31907    1\n3191...850    0\nName: toxic, Length: 63900, dtype: int64, **fit_params={})\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n    248         Xt, fit_params = self._fit(X, y, **fit_params)\n    249         if self._final_estimator is not None:\n--> 250             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method LinearSVC.fit of LinearSVC(C=0, cl...y='l2', random_state=None, tol=1e-05, verbose=0)>\n        Xt = <63900x159435 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>\n        y = 31887    1\n31888    1\n31898    1\n31907    1\n3191...850    0\nName: toxic, Length: 63900, dtype: int64\n        fit_params = {}\n    251         return self\n    252 \n    253     def fit_transform(self, X, y=None, **fit_params):\n    254         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/svm/classes.py in fit(self=LinearSVC(C=0, class_weight=None, dual=True, fit...ty='l2', random_state=None, tol=1e-05, verbose=0), X=<63900x159435 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, y=array([1, 1, 1, ..., 0, 0, 0]), sample_weight=None)\n    230 \n    231         self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n    232             X, y, self.C, self.fit_intercept, self.intercept_scaling,\n    233             self.class_weight, self.penalty, self.dual, self.verbose,\n    234             self.max_iter, self.tol, self.random_state, self.multi_class,\n--> 235             self.loss, sample_weight=sample_weight)\n        self.loss = 'hinge'\n        sample_weight = None\n    236 \n    237         if self.multi_class == \"crammer_singer\" and len(self.classes_) == 2:\n    238             self.coef_ = (self.coef_[1] - self.coef_[0]).reshape(1, -1)\n    239             if self.fit_intercept:\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py in _fit_liblinear(X=<63900x159435 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, y=array([1, 1, 1, ..., 0, 0, 0]), C=0, fit_intercept=True, intercept_scaling=1, class_weight=None, penalty='l2', dual=True, verbose=0, max_iter=1000, tol=1e-05, random_state=None, multi_class='ovr', loss='hinge', epsilon=0.1, sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.]))\n    885 \n    886     solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n    887     raw_coef_, n_iter_ = liblinear.train_wrap(\n    888         X, y_ind, sp.isspmatrix(X), solver_type, tol, bias, C,\n    889         class_weight_, max_iter, rnd.randint(np.iinfo('i').max),\n--> 890         epsilon, sample_weight)\n        epsilon = 0.1\n        sample_weight = array([ 1.,  1.,  1., ...,  1.,  1.,  1.])\n    891     # Regarding rnd.randint(..) in the above signature:\n    892     # seed for srand in range [0..INT_MAX); due to limitations in Numpy\n    893     # on 32-bit platforms, we can't get to the UINT_MAX limit that\n    894     # srand supports\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/svm/liblinear.cpython-36m-darwin.so in sklearn.svm.liblinear.train_wrap()\n\nValueError: b'C <= 0'\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Thu Dec 28 18:56:16 2017\nPID: 3178                               Python 3.6.3: /anaconda3/bin/python\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('tfidf', Tfid...'l2', random_state=None, tol=1e-05, verbose=0))]), 0        nonsense  kiss off geek what i said is ...\nName: comment_text, Length: 95851, dtype: object, 0        1\n1        0\n2        0\n3        0\n4   ...850    0\nName: toxic, Length: 95851, dtype: int64, {'score': <function _passthrough_scorer>}, array([31887, 31888, 31898, ..., 95848, 95849, 95850]), array([    0,     1,     2, ..., 31964, 31965, 31966]), 0, {'svc__C': 0, 'svc__tol': 1e-05}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('tfidf', Tfid...'l2', random_state=None, tol=1e-05, verbose=0))]), 0        nonsense  kiss off geek what i said is ...\nName: comment_text, Length: 95851, dtype: object, 0        1\n1        0\n2        0\n3        0\n4   ...850    0\nName: toxic, Length: 95851, dtype: int64, {'score': <function _passthrough_scorer>}, array([31887, 31888, 31898, ..., 95848, 95849, 95850]), array([    0,     1,     2, ..., 31964, 31965, 31966]), 0, {'svc__C': 0, 'svc__tol': 1e-05})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...'l2', random_state=None, tol=1e-05, verbose=0))]), X=0        nonsense  kiss off geek what i said is ...\nName: comment_text, Length: 95851, dtype: object, y=0        1\n1        0\n2        0\n3        0\n4   ...850    0\nName: toxic, Length: 95851, dtype: int64, scorer={'score': <function _passthrough_scorer>}, train=array([31887, 31888, 31898, ..., 95848, 95849, 95850]), test=array([    0,     1,     2, ..., 31964, 31965, 31966]), verbose=0, parameters={'svc__C': 0, 'svc__tol': 1e-05}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...l2', random_state=None, tol=1e-05, verbose=0))])>\n        X_train = 31887    you are  really a dishonest person ive ...\nName: comment_text, Length: 63900, dtype: object\n        y_train = 31887    1\n31888    1\n31898    1\n31907    1\n3191...850    0\nName: toxic, Length: 63900, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...'l2', random_state=None, tol=1e-05, verbose=0))]), X=31887    you are  really a dishonest person ive ...\nName: comment_text, Length: 63900, dtype: object, y=31887    1\n31888    1\n31898    1\n31907    1\n3191...850    0\nName: toxic, Length: 63900, dtype: int64, **fit_params={})\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n    248         Xt, fit_params = self._fit(X, y, **fit_params)\n    249         if self._final_estimator is not None:\n--> 250             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method LinearSVC.fit of LinearSVC(C=0, cl...y='l2', random_state=None, tol=1e-05, verbose=0)>\n        Xt = <63900x159435 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>\n        y = 31887    1\n31888    1\n31898    1\n31907    1\n3191...850    0\nName: toxic, Length: 63900, dtype: int64\n        fit_params = {}\n    251         return self\n    252 \n    253     def fit_transform(self, X, y=None, **fit_params):\n    254         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/svm/classes.py in fit(self=LinearSVC(C=0, class_weight=None, dual=True, fit...ty='l2', random_state=None, tol=1e-05, verbose=0), X=<63900x159435 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, y=array([1, 1, 1, ..., 0, 0, 0]), sample_weight=None)\n    230 \n    231         self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n    232             X, y, self.C, self.fit_intercept, self.intercept_scaling,\n    233             self.class_weight, self.penalty, self.dual, self.verbose,\n    234             self.max_iter, self.tol, self.random_state, self.multi_class,\n--> 235             self.loss, sample_weight=sample_weight)\n        self.loss = 'hinge'\n        sample_weight = None\n    236 \n    237         if self.multi_class == \"crammer_singer\" and len(self.classes_) == 2:\n    238             self.coef_ = (self.coef_[1] - self.coef_[0]).reshape(1, -1)\n    239             if self.fit_intercept:\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py in _fit_liblinear(X=<63900x159435 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, y=array([1, 1, 1, ..., 0, 0, 0]), C=0, fit_intercept=True, intercept_scaling=1, class_weight=None, penalty='l2', dual=True, verbose=0, max_iter=1000, tol=1e-05, random_state=None, multi_class='ovr', loss='hinge', epsilon=0.1, sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.]))\n    885 \n    886     solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n    887     raw_coef_, n_iter_ = liblinear.train_wrap(\n    888         X, y_ind, sp.isspmatrix(X), solver_type, tol, bias, C,\n    889         class_weight_, max_iter, rnd.randint(np.iinfo('i').max),\n--> 890         epsilon, sample_weight)\n        epsilon = 0.1\n        sample_weight = array([ 1.,  1.,  1., ...,  1.,  1.,  1.])\n    891     # Regarding rnd.randint(..) in the above signature:\n    892     # seed for srand in range [0..INT_MAX); due to limitations in Numpy\n    893     # on 32-bit platforms, we can't get to the UINT_MAX limit that\n    894     # srand supports\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/svm/liblinear.cpython-36m-darwin.so in sklearn.svm.liblinear.train_wrap()\n\nValueError: b'C <= 0'\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-a075af577231>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'svc__tol'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'svc__C'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgs_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgs_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comment_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'toxic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x10cdfcd20, file \"/ana...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10cdfcd20, file \"/ana...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"parameters = {'svc__tol': [1e-5,1e-2], 'svc__C':..._clf.fit(train['comment_text'], train['toxic'])\\n\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 29, 0, 56, 5, 999549, tzinfo=tzutc()), 'msg_id': '140F2A2F11954948953760F92639355D', 'msg_type': 'execute_request', 'session': '421A6F6215CC4FD2884C42E370C07DCB', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '140F2A2F11954948953760F92639355D', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'421A6F6215CC4FD2884C42E370C07DCB']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"parameters = {'svc__tol': [1e-5,1e-2], 'svc__C':..._clf.fit(train['comment_text'], train['toxic'])\\n\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 29, 0, 56, 5, 999549, tzinfo=tzutc()), 'msg_id': '140F2A2F11954948953760F92639355D', 'msg_type': 'execute_request', 'session': '421A6F6215CC4FD2884C42E370C07DCB', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '140F2A2F11954948953760F92639355D', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'421A6F6215CC4FD2884C42E370C07DCB'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"parameters = {'svc__tol': [1e-5,1e-2], 'svc__C':..._clf.fit(train['comment_text'], train['toxic'])\\n\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 29, 0, 56, 5, 999549, tzinfo=tzutc()), 'msg_id': '140F2A2F11954948953760F92639355D', 'msg_type': 'execute_request', 'session': '421A6F6215CC4FD2884C42E370C07DCB', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '140F2A2F11954948953760F92639355D', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"parameters = {'svc__tol': [1e-5,1e-2], 'svc__C':..._clf.fit(train['comment_text'], train['toxic'])\\n\\n\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"parameters = {'svc__tol': [1e-5,1e-2], 'svc__C':..._clf.fit(train['comment_text'], train['toxic'])\\n\\n\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"parameters = {'svc__tol': [1e-5,1e-2], 'svc__C':..._clf.fit(train['comment_text'], train['toxic'])\\n\\n\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"parameters = {'svc__tol': [1e-5,1e-2], 'svc__C':..._clf.fit(train['comment_text'], train['toxic'])\\n\\n\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"parameters = {'svc__tol': [1e-5,1e-2], 'svc__C':..._clf.fit(train['comment_text'], train['toxic'])\\n\\n\", store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-43-a075af577231>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1a19993198, execution..._before_exec=None error_in_exec=None result=None>)\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n   2807                 code = compiler(mod, cell_name, \"single\")\n-> 2808                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1155830c0, file \"<ipython-input-43-a075af577231>\", line 3>\n        result = <ExecutionResult object at 1a19993198, execution..._before_exec=None error_in_exec=None result=None>\n   2809                     return True\n   2810 \n   2811             # Flush softspace\n   2812             if softspace(sys.stdout, 0):\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1155830c0, file \"<ipython-input-43-a075af577231>\", line 3>, result=<ExecutionResult object at 1a19993198, execution..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1155830c0, file \"<ipython-input-43-a075af577231>\", line 3>\n        self.user_global_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport numpy as np\\nimport st....svm import LinearSVC\\nfrom sklearn.svm import SVC', \"def comments_preprocessing(df):\\n    df['comment_...apply(lambda x: x.replace('\\\\r',''))\\n    return df\", \"train = pd.read_csv('data/train.csv')\\ntrain = co...test shape', test.shape)\\ntrain.head()\\ntest.head()\", 'categories = train.columns.values.tolist()[2:]\\nt...n[x] == 1] for x in categories]\\nprint(categories)', \"predictions = pd.DataFrame({'id': test['id']})\\n\\n...s shape', predictions.shape)\\npredictions.head(20)\", \"predictions = pd.DataFrame({'id': test['id']})\\n\\n...s shape', predictions.shape)\\npredictions.head(20)\", \"print('amount marked true in each category')\\nfor... = predictions[name].sum()\\n    print(name, total)\", \"print('amount marked true in each category')\\nfor... = predictions[name].sum()\\n    print(name, total)\", 'import pandas as pd\\nimport numpy as np\\nimport st...\\nfrom sklearn.model_selection import GridSearchCV', 'import pandas as pd\\nimport numpy as np\\nimport st...\\nfrom sklearn.model_selection import GridSearchCV', 'import pandas as pd\\nimport numpy as np\\nimport st...\\nfrom sklearn.model_selection import GridSearchCV', \"def comments_preprocessing(df):\\n    df['comment_...apply(lambda x: x.replace('\\\\r',''))\\n    return df\", \"train = pd.read_csv('data/train.csv')\\ntrain = co...test shape', test.shape)\\ntrain.head()\\ntest.head()\", 'categories = train.columns.values.tolist()[2:]\\nt...n[x] == 1] for x in categories]\\nprint(categories)', \"parameters = {'C': (-1,1), 'tol': (1e-4,1e-2))}\\n... % (param_name, gs_clf.best_params_[param_name]))\", \"parameters = {'C': (-1,1), 'tol': (1e-4,1e-2)}\\nf... % (param_name, gs_clf.best_params_[param_name]))\", \"parameters = {'C': (0,1), 'tol': (1e-4,1e-2)}\\nfo... % (param_name, gs_clf.best_params_[param_name]))\", \"parameters = {'tol': (1e-4,1e-2)}\\nfor name in ca... % (param_name, gs_clf.best_params_[param_name]))\", \"parameters = {'svc__tol': (1e-4,1e-2)}\\nfor name ... % (param_name, gs_clf.best_params_[param_name]))\", ...], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'Out': {3:          id                                     ...                              wikilink talkcelts , 5:           id  toxic  severe_toxic  obscene  thre...        0        0       0       0              0, 6:           id  toxic  severe_toxic  obscene  thre...        0        0       0       0              0, 13:          id                                     ...                              wikilink talkcelts , 21:          id                                     ...                              wikilink talkcelts , 23:           id  toxic  severe_toxic  obscene  thre...        0        0       0       0              0, 36: GridSearchCV(cv=None, error_score='raise',\n     ...turn_train_score='warn', scoring=None, verbose=0)}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'TfidfTransformer': <class 'sklearn.feature_extraction.text.TfidfTransformer'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, '_': GridSearchCV(cv=None, error_score='raise',\n     ...turn_train_score='warn', scoring=None, verbose=0), ...}\n        self.user_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport numpy as np\\nimport st....svm import LinearSVC\\nfrom sklearn.svm import SVC', \"def comments_preprocessing(df):\\n    df['comment_...apply(lambda x: x.replace('\\\\r',''))\\n    return df\", \"train = pd.read_csv('data/train.csv')\\ntrain = co...test shape', test.shape)\\ntrain.head()\\ntest.head()\", 'categories = train.columns.values.tolist()[2:]\\nt...n[x] == 1] for x in categories]\\nprint(categories)', \"predictions = pd.DataFrame({'id': test['id']})\\n\\n...s shape', predictions.shape)\\npredictions.head(20)\", \"predictions = pd.DataFrame({'id': test['id']})\\n\\n...s shape', predictions.shape)\\npredictions.head(20)\", \"print('amount marked true in each category')\\nfor... = predictions[name].sum()\\n    print(name, total)\", \"print('amount marked true in each category')\\nfor... = predictions[name].sum()\\n    print(name, total)\", 'import pandas as pd\\nimport numpy as np\\nimport st...\\nfrom sklearn.model_selection import GridSearchCV', 'import pandas as pd\\nimport numpy as np\\nimport st...\\nfrom sklearn.model_selection import GridSearchCV', 'import pandas as pd\\nimport numpy as np\\nimport st...\\nfrom sklearn.model_selection import GridSearchCV', \"def comments_preprocessing(df):\\n    df['comment_...apply(lambda x: x.replace('\\\\r',''))\\n    return df\", \"train = pd.read_csv('data/train.csv')\\ntrain = co...test shape', test.shape)\\ntrain.head()\\ntest.head()\", 'categories = train.columns.values.tolist()[2:]\\nt...n[x] == 1] for x in categories]\\nprint(categories)', \"parameters = {'C': (-1,1), 'tol': (1e-4,1e-2))}\\n... % (param_name, gs_clf.best_params_[param_name]))\", \"parameters = {'C': (-1,1), 'tol': (1e-4,1e-2)}\\nf... % (param_name, gs_clf.best_params_[param_name]))\", \"parameters = {'C': (0,1), 'tol': (1e-4,1e-2)}\\nfo... % (param_name, gs_clf.best_params_[param_name]))\", \"parameters = {'tol': (1e-4,1e-2)}\\nfor name in ca... % (param_name, gs_clf.best_params_[param_name]))\", \"parameters = {'svc__tol': (1e-4,1e-2)}\\nfor name ... % (param_name, gs_clf.best_params_[param_name]))\", ...], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'Out': {3:          id                                     ...                              wikilink talkcelts , 5:           id  toxic  severe_toxic  obscene  thre...        0        0       0       0              0, 6:           id  toxic  severe_toxic  obscene  thre...        0        0       0       0              0, 13:          id                                     ...                              wikilink talkcelts , 21:          id                                     ...                              wikilink talkcelts , 23:           id  toxic  severe_toxic  obscene  thre...        0        0       0       0              0, 36: GridSearchCV(cv=None, error_score='raise',\n     ...turn_train_score='warn', scoring=None, verbose=0)}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'TfidfTransformer': <class 'sklearn.feature_extraction.text.TfidfTransformer'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, '_': GridSearchCV(cv=None, error_score='raise',\n     ...turn_train_score='warn', scoring=None, verbose=0), ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/Users/alanliang/Desktop/toxic_comments/<ipython-input-43-a075af577231> in <module>()\n      1 parameters = {'svc__tol': [1e-5,1e-2], 'svc__C':[0,1]}\n      2 gs_clf = GridSearchCV(clf, parameters, n_jobs = -1)\n----> 3 gs_clf.fit(train['comment_text'], train['toxic'])\n      4 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...ain_score='warn',\n       scoring=None, verbose=0), X=0        nonsense  kiss off geek what i said is ...\nName: comment_text, Length: 95851, dtype: object, y=0        1\n1        0\n2        0\n3        0\n4   ...850    0\nName: toxic, Length: 95851, dtype: int64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = 0        nonsense  kiss off geek what i said is ...\nName: comment_text, Length: 95851, dtype: object\n        y = 0        1\n1        0\n2        0\n3        0\n4   ...850    0\nName: toxic, Length: 95851, dtype: int64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Thu Dec 28 18:56:16 2017\nPID: 3178                               Python 3.6.3: /anaconda3/bin/python\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('tfidf', Tfid...'l2', random_state=None, tol=1e-05, verbose=0))]), 0        nonsense  kiss off geek what i said is ...\nName: comment_text, Length: 95851, dtype: object, 0        1\n1        0\n2        0\n3        0\n4   ...850    0\nName: toxic, Length: 95851, dtype: int64, {'score': <function _passthrough_scorer>}, array([31887, 31888, 31898, ..., 95848, 95849, 95850]), array([    0,     1,     2, ..., 31964, 31965, 31966]), 0, {'svc__C': 0, 'svc__tol': 1e-05}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('tfidf', Tfid...'l2', random_state=None, tol=1e-05, verbose=0))]), 0        nonsense  kiss off geek what i said is ...\nName: comment_text, Length: 95851, dtype: object, 0        1\n1        0\n2        0\n3        0\n4   ...850    0\nName: toxic, Length: 95851, dtype: int64, {'score': <function _passthrough_scorer>}, array([31887, 31888, 31898, ..., 95848, 95849, 95850]), array([    0,     1,     2, ..., 31964, 31965, 31966]), 0, {'svc__C': 0, 'svc__tol': 1e-05})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...'l2', random_state=None, tol=1e-05, verbose=0))]), X=0        nonsense  kiss off geek what i said is ...\nName: comment_text, Length: 95851, dtype: object, y=0        1\n1        0\n2        0\n3        0\n4   ...850    0\nName: toxic, Length: 95851, dtype: int64, scorer={'score': <function _passthrough_scorer>}, train=array([31887, 31888, 31898, ..., 95848, 95849, 95850]), test=array([    0,     1,     2, ..., 31964, 31965, 31966]), verbose=0, parameters={'svc__C': 0, 'svc__tol': 1e-05}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...l2', random_state=None, tol=1e-05, verbose=0))])>\n        X_train = 31887    you are  really a dishonest person ive ...\nName: comment_text, Length: 63900, dtype: object\n        y_train = 31887    1\n31888    1\n31898    1\n31907    1\n3191...850    0\nName: toxic, Length: 63900, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...'l2', random_state=None, tol=1e-05, verbose=0))]), X=31887    you are  really a dishonest person ive ...\nName: comment_text, Length: 63900, dtype: object, y=31887    1\n31888    1\n31898    1\n31907    1\n3191...850    0\nName: toxic, Length: 63900, dtype: int64, **fit_params={})\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n    248         Xt, fit_params = self._fit(X, y, **fit_params)\n    249         if self._final_estimator is not None:\n--> 250             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method LinearSVC.fit of LinearSVC(C=0, cl...y='l2', random_state=None, tol=1e-05, verbose=0)>\n        Xt = <63900x159435 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>\n        y = 31887    1\n31888    1\n31898    1\n31907    1\n3191...850    0\nName: toxic, Length: 63900, dtype: int64\n        fit_params = {}\n    251         return self\n    252 \n    253     def fit_transform(self, X, y=None, **fit_params):\n    254         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/svm/classes.py in fit(self=LinearSVC(C=0, class_weight=None, dual=True, fit...ty='l2', random_state=None, tol=1e-05, verbose=0), X=<63900x159435 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, y=array([1, 1, 1, ..., 0, 0, 0]), sample_weight=None)\n    230 \n    231         self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n    232             X, y, self.C, self.fit_intercept, self.intercept_scaling,\n    233             self.class_weight, self.penalty, self.dual, self.verbose,\n    234             self.max_iter, self.tol, self.random_state, self.multi_class,\n--> 235             self.loss, sample_weight=sample_weight)\n        self.loss = 'hinge'\n        sample_weight = None\n    236 \n    237         if self.multi_class == \"crammer_singer\" and len(self.classes_) == 2:\n    238             self.coef_ = (self.coef_[1] - self.coef_[0]).reshape(1, -1)\n    239             if self.fit_intercept:\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py in _fit_liblinear(X=<63900x159435 sparse matrix of type '<class 'num... stored elements in Compressed Sparse Row format>, y=array([1, 1, 1, ..., 0, 0, 0]), C=0, fit_intercept=True, intercept_scaling=1, class_weight=None, penalty='l2', dual=True, verbose=0, max_iter=1000, tol=1e-05, random_state=None, multi_class='ovr', loss='hinge', epsilon=0.1, sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.]))\n    885 \n    886     solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n    887     raw_coef_, n_iter_ = liblinear.train_wrap(\n    888         X, y_ind, sp.isspmatrix(X), solver_type, tol, bias, C,\n    889         class_weight_, max_iter, rnd.randint(np.iinfo('i').max),\n--> 890         epsilon, sample_weight)\n        epsilon = 0.1\n        sample_weight = array([ 1.,  1.,  1., ...,  1.,  1.,  1.])\n    891     # Regarding rnd.randint(..) in the above signature:\n    892     # seed for srand in range [0..INT_MAX); due to limitations in Numpy\n    893     # on 32-bit platforms, we can't get to the UINT_MAX limit that\n    894     # srand supports\n\n...........................................................................\n/anaconda3/lib/python3.6/site-packages/sklearn/svm/liblinear.cpython-36m-darwin.so in sklearn.svm.liblinear.train_wrap()\n\nValueError: b'C <= 0'\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "parameters = {'svc__tol': [1e-5,1e-2], 'svc__C':[0,1]}\n",
    "gs_clf = GridSearchCV(clf, parameters, n_jobs = -1)\n",
    "gs_clf.fit(train['comment_text'], train['toxic'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__tol': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "print(gs_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount marked true in each category\n",
      "toxic 5617\n",
      "severe_toxic 179\n",
      "obscene 3190\n",
      "threat 44\n",
      "insult 2728\n",
      "identity_hate 159\n"
     ]
    }
   ],
   "source": [
    "print('amount marked true in each category')\n",
    "for name in categories:\n",
    "    total = predictions[name].sum()\n",
    "    print(name, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TOXIC ---\n",
      "-  stop being a foolif hes going to post up racist lies and claim hes following policy im going to call that fool feldspar what he is a racist fool\n",
      "-  what right do you have to block the whites people including myself when you ethnic european and ethnic african descents are the most racist and belicuse creatures on my planet which planet you come from said chooyooo was rude and impolite than anything i wrote who or what ethnicity is he trying to insult with his ridiculous usertalkyou bizarre stubborn and desperate act of ethnic european ironfist censorship thats what it is will only succeed to increase my determination and drive to break the back of western racism paraphrase the negro or ethnic african doctor kings in the 60sif you continue to block whites as myself youre only succeeding in demonstrating your ethnic european desperate cunnings and or western despotism why do you show what kind blond yoke you are with your lowly blond perils and socalled white maggots\n",
      "-  i wish the euro74rash would stop fucking up jewish articles only jews should be allowed to edit jewish articles because the fucking antisemites who run wikipedia cant be trustedjust look at the garbage this dutchman is doing httpenwikipediaorgwindexphptitlekatzrindiff607502596oldid607494715\n",
      "-  unblockmaterial scientist isa dum dum and so is pbass607 yolo swag they are both gay with each other\n",
      "-  i reckon you should die\n",
      "-  your agendayou are the one going around assuming peoples ethnicity who are you to say this is this and that is that im on to your racist agenda\n",
      "--- SEVERE_TOXIC ---\n",
      "-  atlan u fucker fuck u im gonna cut off your cock and fry it with onions and lick it and bite it off im gonna bite off ur cock and youre gonna be deaaaaad fucker\n",
      "-  hey will how bout u suck my dick d try to fckin mutha fckin messgae me u fat ass mutha fucker redo my page again i  dare umutha fcker ass bitch whore cat lickin cheese ball\n",
      "-  youre my hero go fuck yourself you fucking boyscout\n",
      "-  bitch you are a fucking hore you suck dick you big ass hole you are gay you faggot ass bitch you can go to hell you bitch ass motherfucker suck a big dick asshole im fuckin your mom ho she cant get off my dick your daddy probably raped you in the ass everyday when you were young you stupid ass motherfuck\n",
      "-  nigger fuck you faggot\n",
      "-  fuck you fuck you fuck you assholes this is bullshit\n",
      "--- OBSCENE ---\n",
      "-  i wish the euro74rash would stop fucking up jewish articles only jews should be allowed to edit jewish articles because the fucking antisemites who run wikipedia cant be trustedjust look at the garbage this dutchman is doing httpenwikipediaorgwindexphptitlekatzrindiff607502596oldid607494715\n",
      "-  this is for youif you deleted that article  you know which article im talking about them may you die you fukin bitch cocksusker\n",
      "-  censorship why is this article constantly being censored by zionist hawks isnt this supposed to be an evenhanded analysis phony propagandists like jayjg espouse their bullshit views which are contrary to the views of the international community via the unhuman rights groups etc etc are ruining wikipedia and turning it into another arm of the israel lobby any criticism is deemed a conspiracy theory you are ruining everything this site is supposed to stand for fucking nazis\n",
      "-  get your cock out of your mothers ass so the nigger can get his back in ban me you pussy\n",
      "-  dear stupid idiot dear mr hq what kind of a stupid name is that all i ask for is that you actually not you but a person with brains review my edits after i am done not during  my edits i have asked you to do so several times is it too much to ask of a proamerican or addaled brain such as yours\n",
      "-  sucks template\n",
      "--- THREAT ---\n",
      "-  i reckon you should die\n",
      "-  should kill myself\n",
      "-  die you washed up hasbeen\n",
      "-  i should try to track down your ip so i can burn your house down you irritating and loathesome little shit who the fuck who dyou think you are i wish i knew who yo uwere so i could beat the everliving shit out of you you fucking whiny annoying loser stop watching star trek reruns and get laid you fucking pussy ass pansy i hope you fucking get aids and cancer at the same time\n",
      "-  you fucking nigger how dare you revert my edits ill hunt you down and rape you until you shit your internal organs out\n",
      "-  hello eat shit and die you cunt\n",
      "--- INSULT ---\n",
      "-  lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent been banned yet bitch go vandalism lmao what weak threats i havent\n",
      "-  this is for youif you deleted that article  you know which article im talking about them may you die you fukin bitch cocksusker\n",
      "-  get your cock out of your mothers ass so the nigger can get his back in ban me you pussy\n",
      "-  dear stupid idiot dear mr hq what kind of a stupid name is that all i ask for is that you actually not you but a person with brains review my edits after i am done not during  my edits i have asked you to do so several times is it too much to ask of a proamerican or addaled brain such as yours\n",
      "-  fuck you the iowa idiots are a real baseball team  signedpėņışmåń\n",
      "-  leave me alone shut up you low life loser and do not write to me  ilovedirtbikes\n",
      "--- IDENTITY_HATE ---\n",
      "-  get your cock out of your mothers ass so the nigger can get his back in ban me you pussy\n",
      "-  you are a homo a big homo\n",
      "-  bitch you are a fucking hore you suck dick you big ass hole you are gay you faggot ass bitch you can go to hell you bitch ass motherfucker suck a big dick asshole im fuckin your mom ho she cant get off my dick your daddy probably raped you in the ass everyday when you were young you stupid ass motherfuck\n",
      "-  you are gay faggot trying to block my ass im behind seven proxies\n",
      "-  nigger fuck you faggot\n",
      "-  ahem nigger nigger nigger nigger nigger nigger nigger thank you  \n"
     ]
    }
   ],
   "source": [
    "# samples of comments that were marked true\n",
    "for name in categories:\n",
    "    print('---', name.upper(), '---')\n",
    "    cond = predictions[name] == True\n",
    "    df = predictions[cond]\n",
    "    count = 0\n",
    "    for index, row in df.iterrows():\n",
    "        print('- ', test[test['id'] == row['id']]['comment_text'].tolist()[0])\n",
    "        count += 1\n",
    "        if count > 5:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output to csv\n",
    "predictions.to_csv('submissions/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.BufferedReader name='submissions/submission.csv'>\n"
     ]
    }
   ],
   "source": [
    "with open('submissions/submission.csv', 'rb') as f:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
